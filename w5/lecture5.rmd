---
title: "Lecture 5"
author: "Michal Kubi&#353;ta"
date: "5 February 2018"
output:
  ioslides_presentation:
    widescreen: yes
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, ffmpeg.format = "mp4",
                      cache = TRUE)
library(magrittr)
library(ggplot2)
library(gganimate)
# library(gridExtra)
```

## Structure
1. Regression
2. Pricing

# Regression

##  {.flexbox .vcenter}

<font size="24" color="orange"> **You tell me...**  
recall you statistics / econometrics class </font>

## Econometric approach
OLS

- statistical method
- assumptions (Gauss-Markov)
    1. linear relationship
        - transformations
    2. zero expected error ($E(\epsilon_{i}) = 0$)
        - intercept
    3. no perfect multicollinearity (full X matrix rank)
    4. <font color="orange">**homoskedasticity**</font> ($E(\epsilon_{i}^{2}) = const$)
        - slope
        
## OLS estimation
$$\hat\beta = (X^{T}X)^{-1}X^{T}y$$
**n** observations, **k** variables (\* = OK for small **k**)

- $X^T \; complextity \; O(nk)$ *
- $X^{T}X = T_{k*k} \; complexity \; O(n^{2})$ <font color="red">**!**</font>
- $T^{-1} = U_{k*k} \; complexity \; O(k^{3})$ *
- $UX^{T} = V_{k*n} \; complexity \; O(k^{2}n)$ *
- $Vy = W_{k*1} \; complexity \; O(kn)$ *

>- what if **k** is not small?


## Setup the estimation of the linear relationship
 how to uniquely describe a line (2D) ?
 
>- 2 parameters, slope and a point
>- there is only 1 parameter to estimate - why?
>- $(\bar X,\bar Y)$
>- optimisation task

## (i) random guess

```{r rndAnim, fig.show='animate'}
rand <- list()

xhat <- mean(mtcars$drat)
yhat <- mean(mtcars$wt)
xmin <- min(mtcars$drat)
xmax <- max(mtcars$drat)

for(i in 1:10){
  slope <- runif(1,-10,10)
  ymax <- yhat + slope*(xmax - xhat)
  ymin <- yhat + slope*(xmin - xhat)
  rand[[i]] <- rbind(c(xmin, ymin, i),c(xmax, ymax, i))
}

rand <- do.call(rbind.data.frame, rand)
colnames(rand) <- c("x","y","iter")

rndPlot <-
  ggplot(rand, aes(x = x, y = y, frame = iter))+
  geom_line()+
  geom_point(data = mtcars, aes(x = drat, y = wt), inherit.aes = F)

gganimate(rndPlot)
```

## (ii) random guess + evolution

- save the parameters and SSR of first iteration - best estimation
- if other parameters lead to lower SSR
    - rewrite the best estimation
- new estimation close to the parameters of the best estimation 
- <font color="orange">**very simple**</font> MCMC process
  
## (iii) random guess + evolution + reproduction

1. generate many random "estimates" of slope
2. find the best individuals
    - less then threshold SSR
    - or given number of best-fit individuals
3. let them breed
    - averaging, linear combinations
4. find the best individuals of the extended population
5. repeat 3. and 4. until convergence / stopping condition
- simple evolution algorithm

## Evolution estimation

```{r evoAnim, fig.show='animate'}
xhat <- mean(mtcars$drat)
yhat <- mean(mtcars$wt)
xmin <- rep(min(mtcars$drat), 4)
xmax <- rep(max(mtcars$drat), 4)

evo <- list()

for(i in 1:10){
  if(i == 1){
    slope <- runif(10,-10,10)
  } else{
    slope <- c(slope, (slope[1]+slope[-1])/2)
  }
  
  SSR <- c()
  for(j in slope){
    SSR <- c(SSR, sum((mtcars$wt - (mtcars$drat - xhat) * j - yhat)^2))
  }
  
  parents <- order(SSR)[1:4]
  
  slope <- slope[parents]
  
  ymax <- yhat + slope*(xmax - xhat)
  ymin <- yhat + slope*(xmin - xhat)
  iter <- i
  col <- rep(1:4, each = 2)
  
  evo[[i]] <- cbind(c(rbind(xmin,xmax)), c(rbind(ymin, ymax)), iter, col)
  
}
evo <- do.call(rbind.data.frame, evo)
colnames(evo) <- c("x", "y", "iter", "col")


evoPlot <-
  ggplot(evo, aes(x = x, y = y, frame = iter, col = as.factor(col)))+
  geom_line()+
  geom_point(data = mtcars, aes(x = drat, y = wt), inherit.aes = F)+
  theme(legend.position = 'none')

gganimate(evoPlot)
```

## (iv) gradient descent
1. calculate the gradient of the function
    - $SSR = \sum_i (y_{i} - \hat y_{i})^{2} =
    \sum_i (y_{i} - (a + bx_{i}))^{2} =$  
    $\sum_i (y_{i} - (\hat y - b \hat x) - bx_{i})^{2} = \sum_i (y_{i} - \hat y - b(x_{i} - \hat x))^{2}$
    - $\nabla SSR = \frac{\partial SSR}{\partial b} = H(b)$
2. generate initial random "estimate" of slope = $b_{0}$
3. move a little in the direction of the gradient
    - $b_{n} = b_{n-1} - \alpha H(b)$
    - $\alpha = parameter$
4. repeat 3. until convergence / stopping condition

## Differences
- for the purpose of fitting the linear relationship (no inference)
    - no assumptions
- for inference (prediction)
    - mostly care about homoskedasticity & outliers
       - different error function
    - cross-validation
- watch out for local optimas!
    - ABC optimisation

# Pricing

## Type of product
- new products (price setting)
    - refer to any marketing introduction book
        - surveys, focus groups
        - elasticity, competition prices, pricing objectives, ...
    - choosing a similar product as benchmark
- existing products (price corrections)
    - different products (manufacturers)
        - similar to new products
        - benchmarking against similar products
    - same products
        - main focus today
        - enough data properly analyse

## Important concepts
- elasticity
- substitutes & complements
   - cross-elasticity

<font size="24" color="orange"> recall you microeconomics class </font>

## Log-log linear model & elasticities

from elasticity to log-log model  

$E = \frac{\frac{\partial Q}{Q}}
            {\frac{\partial P}{P}} =
     \frac{\partial Q}{\partial P}\frac{P}{Q} \Rightarrow
     \frac{\partial Q}{Q} = E\frac{\partial P}{P}$  
$\ln Q = E \ln P + c \Rightarrow \ln Q = \alpha + \beta \ln P$  
  
</br>  
similarly for cross-elasticities

$ln Q = \alpha + \beta_{0} \ln P_{0} + \beta_{1} \ln P_{1} + \cdots + \beta_{n} \ln P_{n}$  
- $\beta_{j} > 0 \Rightarrow$ substitutes, $j > 0$  
- $\beta_{j} > 0 \Rightarrow$ complements, $j > 0$

## Much ado about elasticities?
- elasticity coefficient
    - profit development in price change
    - determines price change desirability
    - insufficient on it's own
- adding price index
    - product relative price
    - determines the price change direction
- together:
    - where I want to move the price
    - is it desirable
    
## PIE matrix
- not a technical term
- PriceIndex-Elasticity matrix
```{r PIE_sample, fig.height = 4, fig.align='center'}
set.seed(1438)
pieMat <- data.frame(id = c(1:20), pi = sample(1:3,20,TRUE), e = sample(1:3,20,TRUE))

ggplot(pieMat, aes(x = pi, y = e, col = as.factor(id)))+
  geom_jitter(width = 0.1, height = 0.1)+
  scale_y_continuous(breaks = 0.5:3.5, limits = c(0.63,3.37))+
  scale_x_continuous(breaks = 0.5:3.5, limits = c(0.63,3.37))+
  theme(panel.grid.major = element_line(color = "black"),
        legend.position = "none",
        axis.text = element_blank(),
        axis.ticks = element_blank())




```

## PIE matrix interpretation
```{r PIE_explained, fig.align='center', fig.width = 8, fig.height = 5}
ggplot(pieMat, aes(x = pi, y = e, col = as.factor(id)))+
  geom_jitter(width = 0.1, height = 0.1)+
  scale_y_continuous(breaks = 0.5:3.5, limits = c(0.63,3.37))+
  scale_x_continuous(breaks = 0.5:3.5, limits = c(0.63,3.37))+
  geom_rect(xmin=0.5, xmax = 1.5, ymin = 0.5, ymax = 1.5,
            color= "#E99042", alpha = 0, size = 1.5)+
  geom_rect(xmin = 2.5, xmax = 3.5, ymin = 2.5, ymax = 3.5,
            color = "#E99042", alpha = 0, size = 1.5)+
  annotate("segment", x = 1.3, xend= 1.7, y = 1, yend = 1,
           size = 1.2, color = "red2", arrow = arrow())+
  annotate("segment", x = 2.7, xend= 2.3, y = 3, yend = 3,
           size = 1.2, color = "red2", arrow = arrow())+
  theme(panel.grid.major = element_line(color = "black"),
        legend.position = "none",
        axis.text = element_blank(),
        axis.ticks = element_blank())
```

## What is missing?
- the target price is set
- how to achieve it
- how about promotions / discounts
    - everyday low?
    - high-low strategy?

## PENE matrix
- again, no technical term
- PromoElasticity-NopromoElasticity

## PENE matrix interpretation
